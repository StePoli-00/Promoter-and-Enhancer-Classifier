<!-- Improved compatibility of back to top link: See: https://github.com/othneildrew/Best-README-Template/pull/73 -->
<a name="readme-top"></a>
<!--
*** Thanks for checking out the Best-README-Template. If you have a suggestion
*** that would make this better, please fork the repo and create a pull request
*** or simply open an issue with the tag "enhancement".
*** Don't forget to give the project a star!
*** Thanks again! Now go create something AMAZING! :D
-->



<!-- PROJECT SHIELDS -->
<!--
*** I'm using markdown "reference style" links for readability.
*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).
*** See the bottom of this document for the declaration of the reference variables
*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.
*** https://www.markdownguide.org/basic-syntax/#reference-style-links
-->

<h1 align="center">Promoter & Enhancer Classsifier</h1>

<!-- PROJECT LOGO -->

<div align="center">
  <a href="https://github.com/StePoli-00/Promoter-and-Enhancer-Classifier">
    <img src="images/dna.svg" alt="Logo" width="200" height="200">
  </a>
  <p align="center">This Repository contains all the information, <br>code of  Promoter and Enhancer Classifier project</p>
  <a href="https://github.com/StePoli-00/Promoter-and-Enhancer-Classifier"><strong>Explore the docs »</strong></a>
    
  
</div>


# Table of Contents
<!-- TABLE OF CONTENTS -->

<ol style="font-size:18px;">
  <li>
    <a href="#abstract">Abstract</a>
  <li><a href="#installation">Installation</a></li>
    
  
  <li><a href="#data-preparation">Data Preparation</a>
    <ul>
    <li><a href="#embedding-tokenizer">Embedding Tokenizer</a></li>
    <li><a href="#one-hot-encoding">One Hot Encoding</a></li>
    </ul>
  </li>
  
  <li><a href="#training">Training</a></li>
  <li><a href="#testing">Testing</a></li>
  <li><a href="#resut">Results</a></li>
</ol>


## Abstract
Decoding the linguistic intricacies of the genome is a crucial problem in biology,
and pre-trained foundational models such as DNABERT and Nucleotide Transformer have made significant strides in this area. Existing works have largely hinged
on k-mer, fixed-length permutations of A, T, C, and G, as the token of the genome
language due to its simplicity. However, we argue that the computation and sample
inefficiencies introduced by k-mer tokenization are primary obstacles in developing
large genome foundational models. We provide conceptual and empirical insights
into genome tokenization, building on which we propose to replace k-mer tokenization with Byte Pair Encoding (BPE), a statistics-based data compression algorithm
that constructs tokens by iteratively merging the most frequent co-occurring genome
segment in the corpus. <br>
[DNABERT Abstract](https://academic.oup.com/bioinformatics/article/37/15/2112/6128680)
<p align="right">(<a href="#readme-top">back to top</a>)</p>
<!-- ABOUT THE PROJECT 
## About The Project

[![Product Name Screen Shot][product-screenshot]](https://example.com)

Here's a blank template to get started: To avoid retyping too much info. Do a search and replace with your text editor for the following: `github_username`, `repo_name`, `twitter_handle`, `linkedin_username`, `email_client`, `email`, `project_title`, `project_description`

<p align="right">(<a href="#readme-top">back to top</a>)</p>





<p align="right">(<a href="#readme-top">back to top</a>)</p>-->

## Installation
1. Clone the repository
   ```sh
    git clone https://github.com/StePoli-00/Promoter-and-Enhancer-Classifier.git
   ```
2. After cloning move into the folder: 
   ```sh
    cd Promoter-and-Enhancer-Classifier/
   ```
3. Create a conda environment by requirements.txt 
   ```sh
    conda create --name <env> --file requirements.txt
   ```

<p align="right">(<a href="#readme-top">back to top</a>)</p>

## Data Preparation 
Before using our mode first we must create dataset.
Input Data are:
- Token Embedding: are generated by DNABERT Tokenizer
- One Hot Encoding: simple encoding of DNA basis: A = {1,0,0,0}, T = {0,1,0,0}, C = {0,0,1,0} e G = {0,0,0,1}

Depending on which model you want to test you must process data in two distinguish manner.
In this section you will learn how to process both. 
## Common Steps
As first thing to do we must extract our data: promoters and enhancer 
#### Promoter Preprocessing
1. Download the following files: 
- genome file: [GRCh38.p14.genome.fa](https://www.gencodegenes.org/human/)
- bed file: [human_epdnew_xxxxxx.bed](https://epd.expasy.org/epd/get_promoters.php) 
2. Place where you prefer, our suggest is to use `Data` folder to store used for the model 
3. From ` Data_Preparation` run **extract_promoters.py** 

```sh
cd Data_Preparation 
python extract_promoters.py -g <genome_file> -b <bed_file> [-l <promoters length> -o <output_path> ]

where: 
-o is the desired position of the output file
example: 
python extract_promoters.py -g GRCh38.p14.genome.fa -b human_epdnew_VgGtt.bed -l 100 -o Desktop/folder
```
> [!NOTE] 
> By omitting `-l` parameter will cut promoter sequence of  variable length: 5,10,20,100,200,1000,2000.<br>
Except for the Transfomer, all the other model take an input sequence of fixed length. <br>
In your case this `-l` parameter is **mandatory**
####  Enhancer Preprocessing


After the conversion from hg19 to hg38 using https://genome.ucsc.edu/cgi-bin/hgLiftOver, we obtain a .BED file that is a list of all enhancers converted into hg38 format.
This file contains enhancers under the format "chr_name:<start_position> - <end_position>".

1. Into terminal run: 
```sh
 pip3 install biopython
```

The **enhancer_preprocessing.py** takes different mandatories arguments from command line: 
1) option "-b": path bed file (hg38) 
2) option "-f": path fasta file (GRCh38.FASTA 3gb) 
3) option "-e": name of output file (.txt) for the final sequences.


Initially, the script open the .BED file and, using a Gene class (name, start, end) generate an iterative list of Gene.<br>
Moreover, the script open `GRCh38.FASTA` file and with FastaElem class (name, sequence) generate a list of FastaElem. <br> 
With Gene list and FastaElem list, using BioPython library, the script for each Gene into FastaElem (using the specific start,end position), takes the relative sequence of nucleotides and save it on `enhancer.txt` output file.
The enhancer.txt file, at the end, contains all the enhancer with the lenght specify in the initial .BED file in hg38 version. 

```sh
python enhancer_preprocessing.py -b <path_bed_file> -f <path_fasta_file> -e <output_name_enhancer_file>
```


#### Create csv dataset
It contains promoter and enhancer sequence. In the previous folder run **create_csv_dataset.py**
```sh
python create_csv_dataset.py -p <promoter_file> -e <enhancer_file> -o <output_file> -l <promoter_length>

example:
python create_csv_dataset.py -p promoters_100.fa -e enhancers.txt -o dataset.csv -l 100
```
### Embedding Tokenizer
1. Fed csv file into **create_embedding.py**
> [!WARNING] 
> The following file require to be execute with GPU
```sh
python -s <dataset.csv> -d <destination>

example:
python -s data.csv -d Project_Folder/
```
This file will create `Embedding` folder in the destination path provided  which contains `embeddings` and `labels` of our data converted from sequence to embeddings using Tokenizer of DNABert. 

2. run **split_dataset.py** to  create Dataset folder, run the following command: 
```sh
 python split_dataset.py -e <embedding_folder_path> -d <dataset_folder_path> [ -z <embedding_zip_path>]  
example:
python split_dataset.py -e Project/Embedding -d Dataset   
```
> [!NOTE]
> - if you want to use -z option <embedding_zip_path> must have the same name for  embedding_folder_path
> - -z: can be used only if the embedding zip folder is only one.

<p align="right">(<a href="#readme-top">back to top</a>)</p>

### One Hot Encoding
After the common steps run this command to generate OHE Dataset
```sh
python create_datasetOHE.py -s <source_path> -d <destionation_path> -l <sequence_length>

where:
-s: is the csv file obtained at the end of common steps
-d: destionation of Dataset folder
-l: length of the sequence

example: python create_datasetOHE.py -s ..\Data\dataset100.csv -d . -l 100
```
This script will create dataset folder named `Dataset_x` where x is the length passed by -l option.

### Transformer 
In order to use the Transfomer model the steps are:
1. run **extract_promoters.py** without  `-l` option:
```sh
example: 
python extract_promoters.py -g GRCh38.p14.genome.fa -b human_epdnew_VgGtt.bed -o Desktop/folder
```
the output file will be named as `promoters_mixed.fa` <br>

2. run **enhancer_preprocessing.py** will cut enhancer to `maximum sequence length` equal to 1000 because in literature enhancer and promoters have a variabile length of 100-1000 bp.
```sh
python enhancer_preprocessing.py
```
3. run **create_csv_dataset.py** with `-l` equal to 1000 (e.g. `maximum sequence length`) 
```sh
example: 
python create_csv_dataset.py -p promoters_mixed.fa -e enhancers.txt -o dataset.csv -l 1000
```




<p align="right">(<a href="#readme-top">back to top</a>)</p>

## Training
<p align="right">(<a href="#readme-top">back to top</a>)</p>

## Testing
<p align="right">(<a href="#readme-top">back to top</a>)</p>

## View Result
Each training produce an output folder that contains checkpoint and "events.out" files. 
1. Into the terminal run: 
   ```sh
    pip3 install tensorboard
   ```
2. After the installation, into the terminal, cd into the training's output folder.
3. Now, run command:
   ```sh
    tensorboard --logdir <name_of_version_folder> 
   ```
4. This command show graphics about training, test and valiadation accuracy and loss.
<p align="right">(<a href="#readme-top">back to top</a>)</p>

## Performance
<p align="right">(<a href="#readme-top">back to top</a>)</p>


<!-- LICENSE -->
## License

Distributed under the MIT License. See `LICENSE.txt` for more information.

<p align="right">(<a href="#readme-top">back to top</a>)</p>

<!-- CONTACT -->
## Contacts
* Antonio De Blasi - [AntonioDeBlasi-Git](https://github.com/AntonioDeBlasi-Git)
* Francesco Zampirollo - [zampifre](https://github.com/zampifre) 
* Stefano Politanò - [StePoli-00](https://github.com/StePoli-00) 



<!-- ## Project Link
[https://github.com/StePoli-00/Promoter-and-Enhancer-Classifier](https://github.com/StePoli-00/Promoter-and-Enhancer-Classifier)

<p align="right">(<a href="#readme-top">back to top</a>)</p> -->




<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
[contributors-shield]: https://img.shields.io/github/contributors/github_username/repo_name.svg?style=for-the-badge
[contributors-url]: https://github.com/github_username/repo_name/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/github_username/repo_name.svg?style=for-the-badge
[forks-url]: https://github.com/github_username/repo_name/network/members
[stars-shield]: https://img.shields.io/github/stars/github_username/repo_name.svg?style=for-the-badge
[stars-url]: https://github.com/github_username/repo_name/stargazers
[issues-shield]: https://img.shields.io/github/issues/github_username/repo_name.svg?style=for-the-badge
[issues-url]: https://github.com/github_username/repo_name/issues
[license-shield]: https://img.shields.io/github/license/github_username/repo_name.svg?style=for-the-badge
[license-url]: https://github.com/StePoli-00/Promoter-and-Enhancer-Classifier/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555
[linkedin-url]: https://linkedin.com/in/linkedin_username
[product-screenshot]: images/screenshot.png
[Next.js]: https://img.shields.io/badge/next.js-000000?style=for-the-badge&logo=nextdotjs&logoColor=white
[Next-url]: https://nextjs.org/
[React.js]: https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB
[React-url]: https://reactjs.org/
[Vue.js]: https://img.shields.io/badge/Vue.js-35495E?style=for-the-badge&logo=vuedotjs&logoColor=4FC08D
[Vue-url]: https://vuejs.org/
[Angular.io]: https://img.shields.io/badge/Angular-DD0031?style=for-the-badge&logo=angular&logoColor=white
[Angular-url]: https://angular.io/
[Svelte.dev]: https://img.shields.io/badge/Svelte-4A4A55?style=for-the-badge&logo=svelte&logoColor=FF3E00
[Svelte-url]: https://svelte.dev/
[Laravel.com]: https://img.shields.io/badge/Laravel-FF2D20?style=for-the-badge&logo=laravel&logoColor=white
[Laravel-url]: https://laravel.com
[Bootstrap.com]: https://img.shields.io/badge/Bootstrap-563D7C?style=for-the-badge&logo=bootstrap&logoColor=white
[Bootstrap-url]: https://getbootstrap.com
[JQuery.com]: https://img.shields.io/badge/jQuery-0769AD?style=for-the-badge&logo=jquery&logoColor=white
[JQuery-url]: https://jquery.com 
